{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines\n",
    "\n",
    "> *It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience*.\n",
    "> \n",
    "> \\- Albert Einstein,\n",
    "[*often quoted as ‚ÄòEverything should be made as simple as possible, but not simpler‚Äô*, *‚ÄòOn the Method of Theoretical Physics‚Äô, lecture delivered at Oxford, 10 June 1933*](https://www.oxfordreference.com/view/10.1093/acref/9780191826719.001.0001/q-oro-ed4-00003988#:~:text=It%20can%20scarcely%20be%20denied,a%20single%20datum%20of%20experience.&text=The%20eternal%20mystery%20of%20the%20world%20is%20its%20comprehensibility%E2%80%A6)\n",
    "\n",
    " Alguns padr√µes de projeto para solu√ß√£o de competi√ß√µes que o NIASIA identificou at√© agora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fa√ßa r√°pido um modelo ruim, aprenda devagar a melhor√°-lo, e ganhe competi√ß√µes!\n",
    "\n",
    "Um bom resumo deste notebook talvez seja [este post no blog do Emmanuel Ameisen: \"Always start with a stupid model, no exceptions.\"](https://mlpowered.com/posts/start-with-a-stupid-model/), autor do livro 'Building Machine Learning Powered Applications: Going from Idea to Product', ou tamb√©m esse artigo da Google: [Rules of ML](https://developers.google.com/machine-learning/guides/rules-of-ml) (\"Keep the first model simple and get the infrastructure right\").\n",
    "\n",
    "Neste notebook apresentamos argumentos e uma metodologia de errar r√°pido para conseguir acertar em competi√ß√µes de Intelig√™ncia Artificial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nesse notebook o foco n√£o ser√° em aprofundar em ideias ou c√≥digos, nem na valida√ß√£o matem√°tica das propostas feitas aqui. \n",
    "\n",
    "#### Ao contr√°rio, aqui ser√£o apresentados exemplos de como muitos livros, autores e Kagglers encaram  e resolvem problemas de IA e atingem performances iguais ou acima do estado da arte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolvendo problemas com IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na maioria dos livros, cursos e at√© frameworks de implementa√ß√£o de solu√ß√µes em IA, discute-se uma vis√£o geral de como resolver problemas com IA. Essencialmente, modelos de aprendizado de m√°quina s√£o m√©todos matem√°ticos (frequentemente com forte embasamento estat√≠stico) que tomam entradas num√©ricas e predizem uma sa√≠da, seja ela uma determinada classe ou um n√∫mero.\n",
    "\n",
    "Normalmente, o processo para treinar esses modelos consiste em:\n",
    "\n",
    "    1. Adquirir dados (que acreditamos ter potencial para prever *algo*)\n",
    "\n",
    "    2. Identificar caracter√≠sticas estat√≠sticas, anomalias e os tipos desses dados\n",
    "\n",
    "    3. Transformar os dados em uma cole√ß√£o de n√∫meros com alguma rela√ß√£o com *algo* que queremos prever\n",
    "    \n",
    "    4. Escolher um modelo de aprendizado que seja capaz de eventualmente prever esses dados\n",
    "\n",
    "    5. Medir a performance desse modelo\n",
    "\n",
    "    6. Melhorar a performance do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padr√£o de projeto em IA:\n",
    "\n",
    "Agora, veja o √≠ndice de um dos cap√≠tulos do livro 'Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow](./imgs/handson_ml_overview.png) -->\n",
    "\n",
    "<div style = \"height:520px\">\n",
    "    <img src=\"./imgs/handson_ml_overview.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D√™ uma olhada agora nos componentes do ciclo de MLOps da Google, no livro 'Practical MLOps\n",
    "Operationalizing Machine Learning Models':\n",
    "\n",
    ">[(MLOps ou ML Ops √© um conjunto de pr√°ticas que visa implantar e manter modelos de machine learning em produ√ß√£o de forma confi√°vel e eficiente. A palavra √© um composto de \"machine learning\" e a pr√°tica de desenvolvimento cont√≠nuo de DevOps na √°rea de software.)](https://www.google.com/search?q=mlops&sxsrf=ALiCzsYlr6Lajbj_pnIRMp_EcUHZJYf8_A:1658366859510&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjBssX86Yj5AhXdSLgEHQ3CClsQ_AUoAXoECAIQAw&biw=1360&bih=699&dpr=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![](./imgs/google_mlops.png) -->\n",
    "\n",
    "<div style = \"height:520px\" >\n",
    "    <img src=\"./imgs/google_mlops.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por √∫ltimo, veja o ciclo de vida de solu√ß√µes de aprendizado de m√°quina, apresentado no livro 'Machine Learning Design Patterns Solutions to Common Challenges in Data Preparation, Model Building, and MLOps':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./imgs/ml_life_cycle_ml_design_patterns.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway:\n",
    "\n",
    "E ent√£o? Notou algum padr√£o?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem, diante dos livros e tamb√©m de competi√ß√µes (como vou mostrar a seguir), existe uma forte tendencia no mercado e na academia de transformar a proposta, treino e predi√ß√£o de modelos de IA em uma *pipeline* autom√°tica, composta de:\n",
    "\n",
    "    1. EDA (an√°lise explorat√≥ria de dados, *exploratory data analysis*)\n",
    "\n",
    "    2. Engenharia de Caracter√≠sticas\n",
    "\n",
    "    3. Sele√ß√£o de Modelo(s)\n",
    "\n",
    "    4. Treino\n",
    "\n",
    "    5. Predi√ß√£o\n",
    "\n",
    "    6. Retreino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare a lista de passos acima com as imagens e com a lista de passos no in√≠cio dessa se√ß√£o. Estes passos s√£o a ess√™ncia (automatiz√°vel!) do aprendizado de m√°quina.\n",
    "\n",
    "### Seu papel ent√£o como pesquisador, desenvolvedor e competidor √© fazer isso t√£o r√°pido e t√£o bom quanto poss√≠vel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competindo no Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Vimos que *nos livros* esses m√©todos s√£o usados. Mas e no Kaggle?\n",
    "\n",
    "D√™ uma olhada r√°pida nas se√ß√µes [deste notebook](). N√£o se preocupe neste primeiro momento em entender os dados ou os resultados. O foco aqui √© na metodologia deste autor. Notou um padr√£o relacionado √† se√ß√£o anterior?\n",
    "\n",
    "No notebook, em linhas gerais, o autor:\n",
    "\n",
    "    1. Importou e visualizou distribui√ß√µes dos dados\n",
    "\n",
    "    2. Limpou e selecionou aqueles que mais importavam para seu contexto/problema\n",
    "\n",
    "    3. Escolheu n√£o UM mas DOZE modelos diferentes, sendo eles:\n",
    "        - Florestas aleat√≥rias:\n",
    "            1. Linear Regression, \n",
    "            2. Ridge Regression, \n",
    "            3. Support Vector Regression, \n",
    "            4. Random Forest Regressor, \n",
    "            5. Gradient Boosting Regressor, \n",
    "            6. AdaBoost Regressor, \n",
    "            7. XGBoost Regressor.\n",
    "        - Modelos Neurais Profundos:\n",
    "            9. Simple RNN, \n",
    "            10. LSTM, \n",
    "            11. Bidirectional RNN\n",
    "        - Transformers:\n",
    "            11. BERT\n",
    "\n",
    "    4. Treinou todos estes modelos \n",
    "\n",
    "    5. Previu as sa√≠das em banco de valida√ß√£o\n",
    "\n",
    "    6. Escolheu o melhor modelo e utilizou ele para submiss√£o.\n",
    "\n",
    "Tudo isso, em um notebook que executa por completo em 1789.1 segundos (30 minutos)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beleza, um monstro da IA. Como fa√ßo isso? Baby steps. Com certeza esse cara n√£o nasceu escrevendo notebooks Kaggle com 12 modelos treinados, ele aprendeu e realizou cada uma das etapas separadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Problemas em IA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Academia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eis algumas √°reas e problemas que modelos de IA s√£o utilizados para resolver, de acordo com os filtros [no famoso hub de solu√ß√µes Open Source https://huggingface.co/](https://huggingface.co/):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![](./imgs/ml_tasks_huggingface.png) -->\n",
    "\n",
    "<div style = \"max-height:520px\">\n",
    "    <img src=\"./imgs/ml_tasks_huggingface.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarmente, acessando o tamb√©m famoso site agregador de artigos cient√≠ficos com c√≥digos de implementa√ß√µes e datasets [https://paperswithcode.com/sota](https://paperswithcode.com/sota), voc√™ encontr√° centenas de tarefas, agrupadas em:\n",
    "\n",
    "    - Computer Vision\n",
    "    - Natural Language Processing\n",
    "    - Methodology\n",
    "    - Miscellaneous\n",
    "    - Time Series\n",
    "    - Graphs \n",
    "    - Speech\n",
    "    - Playing Games\n",
    "    - Audio\n",
    "    - Computer Code\n",
    "    - Adversarial\n",
    "    - Robots\n",
    "    - Reasoning\n",
    "    - Knowledge Base\n",
    "    - Music\n",
    "\n",
    "Todos estes agrupamentos de tarefas possuem diversas solu√ß√µes, empregando modelos com diferentes par√¢metros, que normalmente tem aplica√ß√£o interdisciplinar e para diferentes tarefas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mercado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al√©m dos agrupamentos de tarefas com base em estrat√©gias acad√™micas, no reposit√≥rio [Awesome Artificial Intelligence use cases](https://github.com/JosPolfliet/awesome-ai-usecases#contents) existem listas de links e recursos agregando problemas de mercado atuais, resolvidos atrav√©s de intelig√™ncia artificial:\n",
    "\n",
    "    Use cases by department\n",
    "\n",
    "    - Call center\n",
    "    - Human Resources\n",
    "    - Finance\n",
    "    - IT\n",
    "    - Marketing\n",
    "    - Sales\n",
    "    - Supply chain\n",
    "\n",
    "    \n",
    "    Use cases by industry\n",
    "\n",
    "    - Banking\n",
    "    - Healthcare\n",
    "    - Insurance\n",
    "    - Life sciences\n",
    "    - Manufacturing\n",
    "    - Public Safety\n",
    "    - Retail\n",
    "    - Telecommunications\n",
    "    - Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deve-se ter cuidado com a curva do Hype, como apresentado em [CLEMMEDSSON, Elin. Identifying pitfalls in machine learning implementation projects: a case study of four technology-intensive organizations. 2018.](http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1230169&dswid=6169):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:520px\">\n",
    "    <img src=\"./imgs/hype_curve_2017.png\",style=\"height:520px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas competi√ß√µes, frequentemente temos ideias mirabolantes de execu√ß√£o dif√≠cil e valida√ß√£o ainda mais dif√≠cil. Busque implementar melhorias pequenas, cuja contribui√ß√£o seja mensur√°vel, para ter controle do impacto que as mudan√ßas que voc√™ prop√¥s teve sobre a sua *pipeline* de preprocessamento, treino ou infer√™ncia. Fa√ßa mudan√ßas pequenas, r√°pidas, o tempo todo, at√© que seu modelo inicial n√£o-t√£o-bom se torne um modelo final vencedor de competi√ß√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumindo: \n",
    "\n",
    "#### Use ao m√°ximo tecnologias prontas, confi√°veis, de comportamento conhecido e que voc√™ domina. Se voc√™ n√£o domina nenhuma, escolha alguma que n√£o seja t√£o complexa e tenha certeza que a entendeu. Passo a passo, aprendemos juntos e atingimos resultados melhores!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se quiser ainda mais recursos e informa√ß√µes, considere ler os links listados no reposit√≥rio [Awesome AI Awesomeness](https://github.com/amusi/awesome-ai-awesomeness#table-of-contents), onde s√£o agrupadas algumas das tarefas e casos de usos dicutidas aqui, al√©m de muitas que nem comentei."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como come√ßar?\n",
    "\n",
    "> Qual modelo faz o que? Quando uso cada um? O que preciso para trein√°-los?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidentemente, n√£o existe resposta exata e completa para nenhuma destas perguntas. Mas assumindo o escopo dos problemas que buscamos resolver atualmente em competi√ß√µes de Kaggle, aqui est√£o alguns recursos e sugest√µes (üî®MARRETAS!) de onde eu comecei, que talvez possam te ajudar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. RTFD (READ THE FUCKING DOCS)\n",
    "\n",
    "> Respire fundo e estude um exemplo antes de desistir de uma abordagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leia sempre as documenta√ß√µes. Grande parte das respostas √† suas perguntas v√£o estar descritas em exemplos e documenta√ß√µes de sites como o da biblioteca [Scikit-Learn](https://scikit-learn.org/stable/index.html):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Sklearn LP](./imgs/sklearn_frontpage.png) -->\n",
    "\n",
    "<div>\n",
    "    <img src=\"./imgs/sklearn_frontpage.png\", alt = 'Sklearn LP',height='520px'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J√° na sua p√°gina inicial a sklearn nos d√° algumas li√ß√µes:\n",
    "\n",
    "- Existem 2 tipos principais de problemas: Classifi√ß√£o e Regress√£o.\n",
    "- Muitas vezes n√£o temos etiquetas (labels) para saber o que deveriamos prever. Para isso, Clustering.\n",
    "- √Äs vezes temos dados demais (muitas dimens√µes) e precisaremos de m√©todos para reduz√≠-las (exemplo: PCA).\n",
    "- Sele√ß√£o de modelos √© importante e existem m√©todos autom√°ticos (mas lentos) para isso.\n",
    "- Preprocessamento (limpeza, normaliza√ß√£o e extra√ß√£o de caracter√≠sticas de dados) √© essencial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ent√£o, antes de desesperar ('Don't panic!' - The Hitchhiker's Guide to the Galaxy), tente buscar no Google: 'sklearn regression example', quando estiver com um problema de regress√£o. E claro, antes de abrir 327 abas da Wikipedia indo de \"Regress√£o\" at√© \"F√≠sica Qu√¢ntica\", considere executar passo a passo um exemplo da biblioteca sklearn. Voc√™ vai se surpreender com qu√£o simples √© usar as ferramentas de l√°!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forests e Boosting\n",
    "\n",
    "> Florestas marreteiras d√£o baseline pra te ajudar a decidir se seu preprocessamento est√° minimamente aceit√°vel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Florestas aleat√≥rias s√£o bastante tendenciosas e podem sofrer com bancos de dados desbalanceados. Mas trein√°-las √© r√°pido, f√°cil e frequentemente √© a primeira na maioria das submiss√µes \"baseline\" em competi√ß√µes Kaggle.\n",
    "\n",
    "Elas recebem como entrada uma tabela com features (caracter√≠sticas) em colunas, e cada entrada (inst√¢ncia de dados) em linhas, sempre num√©ricas. \n",
    "\n",
    "Logo, se voc√™ tem features categ√≥ricas (texto, por exemplo), vai precisar transform√°-las em n√∫meros de alguma forma!\n",
    "\n",
    "Como sa√≠da, estas redes normalmente possuem implementa√ß√µes para tarefas de regress√£o ou classifica√ß√£o. \n",
    "\n",
    "Aqui alguns links (com exemplos para classifica√ß√£o) de bibliotecas de Random Forests muito usadas:\n",
    "\n",
    "- [lightgbm.LGBMClassifier ‚Äî LightGBM 3.3.2.99 documentation](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)\n",
    "- [XGBoost Documentation ‚Äî xgboost 1.6.1 documentation](https://xgboost.readthedocs.io/en/stable/)\n",
    "- [sklearn.ensemble.RandomForestClassifier ‚Äî scikit-learn 1.1.1 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- [sklearn.multiclass.OneVsRestClassifier ‚Äî scikit-learn 1.1.1 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html)\n",
    "- [LightGBM Classifier in Python | Kaggle](https://www.kaggle.com/code/prashant111/lightgbm-classifier-in-python/notebook)\n",
    "\n",
    "\n",
    "Dica: XGBoost tem treino normalmente mais lento que o LGBM, e nem sempre tem uma performance melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perceptron Multicamadas (MLP)\n",
    "\n",
    "> Neur√¥nios s√£o dif√≠ceis de treinar mas podem abstrair padr√µes, diferente das florestas marreteiras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferente das florestas aleat√≥rias, as redes neurais artificiais com base em perceptron multicamadas t√™m a vantagem de serem altamente flex√≠veis e abstrair padr√µes a partir dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.neural_network.MLPClassifier ‚Äî scikit-learn 1.1.1 documentation\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um problema para se atentar treinando redes neurais artificiais, √© a generaliza√ß√£o de padr√µes n√£o desejados, como exemplificado em [GEIRHOS, Robert et al. Shortcut learning in deep neural networks. Nature Machine Intelligence, v. 2, n. 11, p. 665-673, 2020](https://www.nature.com/articles/s42256-020-00257-z):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-height:520px\">\n",
    "    <img src=\"./imgs/dll_unintended_abstractions.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, MLPs rasas e profundas se caracterizam como ferramentas poderosas mas escorregadias. T√™m potencial de atingir aquele 2% a mais que traz a vit√≥ria na competi√ß√£o, mas seu treinamento est√° longe de ser trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Redes Convolucionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kkkkkkk boa sorte, ainda n√£o tive tempo de escrever essa parte (WIP TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Outros m√©todos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kkkkkkk boa sorte, ainda n√£o tive tempo de escrever essa parte (WIP TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Mais recursos e links com exemplos para come√ßar:\n",
    "\n",
    "> OK Boomer. Falou muito, mas onde encontro exemplos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe uma gama enorme de exemplos de preprocessamento, treino de modelos e otimiza√ß√£o notebooks excelentes dispon√≠veis na pr√≥pria plataforma [Kaggle](https://www.kaggle.com/). Escolha um t√≥pico simples por dia, quando menos perceber, vai estar lidando com problemas e resultados bem pr√≥ximos do estado da arte!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas inst√¢ncias de tarefas comuns em IA, exemplificadas e discutidas no livro \"Building Machine Learning Powered Applications: Going from Idea to Product\" est√£o dispon√≠veis no reposit√≥rio: [ml-powered-applications/notebooks at master ¬∑ hundredblocks/ml-powered-applications]\n",
    "(https://github.com/hundredblocks/ml-powered-applications/tree/master/notebooks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem diversos reposit√≥rios com nome \"awesome\" listando recursos para determinadas √°reas de conhecimento: \n",
    "\n",
    "- Em \"[Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning#table-of-contents)\", voc√™ encontrar√° exemplos de implementa√ß√£o e uso de diversas metodologias em aprendizado de m√°quinas, para as linguagens mais populares;\n",
    "\n",
    "- Ainda em \"Awesome Machine Learning\", d√™ uma olhada em livros gr√°tis lidando com diferentes tarefas necess√°rias para construir modelos, listadas nesse link: [https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md](https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md);\n",
    "\n",
    "- Em \"[Awesome AI](https://github.com/MRCIEU/awesome-ai#awesome-ai)\", voc√™ encontrar√° tutoriais, ferramentas e at√© artigos cient√≠ficos explicando diversos conceitos e tecnologias √∫teis para aprender a trabalhar com intelig√™ncia artificial.\n",
    "\n",
    "- Em \"[Awesome Software Engineering for Machine Learning](https://github.com/SE-ML/awesome-seml#contents)\", voc√™ encontrar√° ferramentas, exemplos, tutoriais e artigos para obter uma vis√£o geral do panorama de Aprendizado de M√°quina visando construir modelos para aplica√ß√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erros comuns e como escapar deles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em termos de nomenclatura quais [tipos de erros existem](https://www.expii.com/t/types-of-error-overview-comparison-8112)?\n",
    "\n",
    "<div style=\"height:520px\">\n",
    "    <img src=\"./imgs/types_of_error.jpeg\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui queremos diminuir os erros sistem√°ticos te√≥ricos (sele√ß√£o de modelos), observacionais (sele√ß√£o de features) e instrumentais (treinamento e emprego de modelos). Mas como?\n",
    "\n",
    "Na documenta√ß√£o da biblioteca sklearn, existe um artigo interessante sobre [erros comuns e pr√°ticas recomendadas](https://scikit-learn.org/stable/common_pitfalls.html), frequentemente discutidos em cursos sobre IA. Voc√™ pode ler com mais detalhes no link, mas alguns pontos importantes s√£o:\n",
    "\n",
    "- Preprocesse com pipelines, sempre da mesma maneira, para controlar melhor os ajustes que voc√™ aplica ao seu modelo.\n",
    "- Atente-se para separar bem a sa√≠da e entrada do modelo! \n",
    "- Controle as seeds aleat√≥rias para obter reproducibilidade.\n",
    "- Use valida√ß√£o cruzada para verificar com precis√£o a performance do seu modelo.\n",
    "\n",
    "√â importante tamb√©m conhecer alguns detalhes importantes ao se trabalhar com medidas e transforma√ß√µes estat√≠sticas, para se interpretar corretamente a sua EDA. Leia [neste documento](https://scikit-learn.org/stable/auto_examples/inspection/plot_linear_model_coefficient_interpretation.html) um relat√≥rio sobre interpreta√ß√£o de correla√ß√£o, escala, vari√¢ncia, entre outros. [Um outro artigo interessante na biblioteca sklearn](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py) trata do impacto e comportamento da normaliza√ß√£o de escala e processamento de outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso tenha mais interesse em estudar erros comuns para se preparar para evit√°-los (ou enfrent√°-los), d√™ uma olhada no artigo [LONES, Michael A. How to avoid machine learning pitfalls: a guide for academic researchers. arXiv preprint arXiv:2108.02497, 2021](https://arxiv.org/pdf/2108.02497.pdf), abaixo o sum√°rio dos t√≥picos analisados no trabalho:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:520px\">\n",
    "    <img src=\"./imgs/avoid_pitfalls_paper.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outros recursos e refer√™ncias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CommonLit: EDA + (Most) NLP Techniquesüìö | Kaggle\n",
    "https://www.kaggle.com/code/utcarshagrawal/commonlit-eda-most-nlp-techniques/notebook\n",
    "\n",
    "List of datasets for machine-learning research - Wikipedia\n",
    "https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Human\n",
    "\n",
    "Outline of machine learning - Wikipedia\n",
    "https://en.wikipedia.org/wiki/Outline_of_machine_learning\n",
    "\n",
    "Models - Hugging Face\n",
    "https://huggingface.co/models?sort=downloads\n",
    "\n",
    "scikit-learn: machine learning in Python ‚Äî scikit-learn 1.1.1 documentation\n",
    "https://scikit-learn.org/stable/index.html\n",
    "\n",
    "Ensemble deep learning in bioinformatics | Nature Machine Intelligence\n",
    "https://www.nature.com/articles/s42256-020-0217-y\n",
    "\n",
    "A Brief Introduction to Probability & Statistics\n",
    "https://betterexplained.com/articles/a-brief-introduction-to-probability-statistics/\n",
    "\n",
    "Shanky-21/Data_visualization\n",
    "https://github.com/Shanky-21/Data_visualization\n",
    "\n",
    "The Intuition Behind Correlation ‚Äì Time Series Analysis, Regression and Forecasting\n",
    "https://timeseriesreasoning.com/contents/correlation/#:~:text=In%20the%20most%20general%20sense,manner%2C%20most%20of%20the%20time.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dd76241fa2ee905525e0a1efacb16294be0e14843e7f10299cba718b3e5fb2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
